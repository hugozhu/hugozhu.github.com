<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><title>Step-by-Step 实现一个能编程的大模型 - Hugo Zhu's Blog</title>
<meta name=description content="从零开始训练一个专注于 Python 代码生成的小型 LLM"><script type=application/ld+json>{"@context":"http://schema.org","@type":"WebSite","name":"All about Raspberry Pi","url":"https:\/\/hugozhu.site\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Organization","name":"","url":"https:\/\/hugozhu.site\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"https:\/\/hugozhu.site\/","name":"home"}},{"@type":"ListItem","position":3,"item":{"@id":"https:\/\/hugozhu.site\/post\/2026\/120-build-code-llm-from-scratch\/","name":"Step by step 实现一个能编程的大模型"}}]}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Article","author":{"name":""},"headline":"Step-by-Step 实现一个能编程的大模型","description":"你是否好奇过 GitHub Copilot、CodeLlama 这些代码生成模型是如何工作的？本文将带你从零开始，一步步实现一个专注于 Python 代码生成的小型语言模型。通过这个项目，你将深入理解 Transformer 架构、代码 tokenization、以及如何让模型学会\u0026quot;写代码\u0026quot;。\n","inLanguage":"en","wordCount":2874,"datePublished":"2026-02-09T00:00:00\u002b00:00","dateModified":"2026-02-09T00:00:00\u002b00:00","image":"https:\/\/hugozhu.site\/img\/pi.png","keywords":["LLM, deep-learning, python, transformer, code-generation, pytorch"],"mainEntityOfPage":"https:\/\/hugozhu.site\/post\/2026\/120-build-code-llm-from-scratch\/","publisher":{"@type":"Organization","name":"https:\/\/hugozhu.site\/","logo":{"@type":"ImageObject","url":"https:\/\/hugozhu.site\/img\/pi.png","height":60,"width":60}}}</script><meta property="og:title" content="Step-by-Step 实现一个能编程的大模型"><meta property="og:description" content="从零开始训练一个专注于 Python 代码生成的小型 LLM"><meta property="og:image" content="https://hugozhu.site/img/pi.png"><meta property="og:url" content="https://hugozhu.site/post/2026/120-build-code-llm-from-scratch/"><meta property="og:type" content="website"><meta property="og:site_name" content="All about Raspberry Pi"><meta name=twitter:title content="Step-by-Step 实现一个能编程的大模型"><meta name=twitter:description content="从零开始训练一个专注于 Python 代码生成的小型 LLM"><meta name=twitter:image content="https://hugozhu.site/img/pi.png"><meta name=twitter:card content="summary_large_image"><link href=https://hugozhu.site/img/pi.ico rel=icon type=image/x-icon><meta name=generator content="Hugo 0.145.0"><link rel=alternate href=https://hugozhu.site/index.xml type=application/rss+xml title="All about Raspberry Pi"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css integrity=sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI crossorigin=anonymous><link rel=stylesheet href=https://use.fontawesome.com/releases/v6.6.0/css/all.css integrity=sha384-h/hnnw1Bi4nbpD6kE7nYfCXzovi622sY5WBxww8ARKwpdLj5kUWjRuyiXaD1U2JT crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/css/bootstrap.min.css integrity=sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu crossorigin=anonymous><link rel=stylesheet href=https://hugozhu.site/css/main.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic"><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800"><link rel=stylesheet href=https://hugozhu.site/css/highlight.min.css><link rel=stylesheet href=https://hugozhu.site/css/codeblock.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css integrity=sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css integrity=sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R crossorigin=anonymous><script async src="https://www.googletagmanager.com/gtag/js?id=GTM-W88HDMN"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","GTM-W88HDMN")}</script></head><body><nav class="navbar navbar-default navbar-fixed-top navbar-custom"><div class=container-fluid><div class=navbar-header><button type=button class=navbar-toggle data-toggle=collapse data-target=#main-navbar>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span>
</button>
<a class=navbar-brand href=https://hugozhu.site/>All about Raspberry Pi</a></div><div class="collapse navbar-collapse" id=main-navbar><ul class="nav navbar-nav navbar-right"><li><a title=Blog href=/>Blog</a></li><li class=navlinks-container><a class=navlinks-parent role=button tabindex=0>Tools</a><div class=navlinks-children><a href=https://nddapp.com/json-encoder.html>HTML Tools</a>
<a href=https://www.birme.net/>Imaeg Resizing</a>
<a href=https://jwt.io/>JWT Token Tool</a></div></li><li><a title=About href=/page/about/>About</a></li><li><a title=Tags href=/tags>Tags</a></li><li><a href=#modalSearch data-toggle=modal data-target=#modalSearch style=outline:none><span class="hidden-sm hidden-md hidden-lg">Search</span> <span id=searchGlyph class="glyphicon glyphicon-search"></span></a></li></ul></div><div class=avatar-container><div class=avatar-img-border><a title="All about Raspberry Pi" href=https://hugozhu.site/><img class=avatar-img src=https://hugozhu.site/img/pi.png alt="All about Raspberry Pi"></a></div></div></div></nav><div id=modalSearch class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><button type=button class=close data-dismiss=modal>&#215;</button><h4 class=modal-title>Search All about Raspberry Pi</h4></div><div class=modal-body><gcse:search></gcse:search></div><div class=modal-footer><button type=button class="btn btn-default" data-dismiss=modal>Close</button></div></div></div></div><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header class=header-section><div class="intro-header no-img"><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><h1>Step-by-Step 实现一个能编程的大模型</h1><h2 class=post-subheading>从零开始训练一个专注于 Python 代码生成的小型 LLM</h2><span class=post-meta><i class="fas fa-calendar"></i>&nbsp;Posted on February 9, 2026
&nbsp;|&nbsp;<i class="fas fa-clock"></i>&nbsp;14&nbsp;minutes
&nbsp;|&nbsp;<i class="fas fa-book"></i>&nbsp;2874&nbsp;words</span></div></div></div></div></div></header><div class=container role=main><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><article role=main class=blog-post><h4><i>目录:</i></h4><nav id=TableOfContents><ul><li><a href=#为什么要自己实现一个代码模型>为什么要自己实现一个代码模型？</a></li><li><a href=#整体架构概览>整体架构概览</a></li><li><a href=#step-1-数据收集与预处理>Step 1: 数据收集与预处理</a><ul><li><a href=#11-收集-python-代码数据>1.1 收集 Python 代码数据</a></li><li><a href=#12-代码-tokenizer>1.2 代码 Tokenizer</a></li></ul></li><li><a href=#step-2-构建-transformer-模型>Step 2: 构建 Transformer 模型</a><ul><li><a href=#21-模型配置>2.1 模型配置</a></li><li><a href=#22-核心组件实现>2.2 核心组件实现</a></li><li><a href=#23-完整模型>2.3 完整模型</a></li></ul></li><li><a href=#step-3-训练流程>Step 3: 训练流程</a><ul><li><a href=#31-数据集>3.1 数据集</a></li><li><a href=#32-训练器>3.2 训练器</a></li><li><a href=#33-开始训练>3.3 开始训练</a></li></ul></li><li><a href=#step-4-推理与代码生成>Step 4: 推理与代码生成</a></li><li><a href=#评估与改进方向>评估与改进方向</a><ul><li><a href=#评估指标>评估指标</a></li><li><a href=#改进方向>改进方向</a></li></ul></li><li><a href=#总结>总结</a></li></ul></nav><p>你是否好奇过 GitHub Copilot、CodeLlama 这些代码生成模型是如何工作的？本文将带你从零开始，一步步实现一个专注于 Python 代码生成的小型语言模型。通过这个项目，你将深入理解 Transformer 架构、代码 tokenization、以及如何让模型学会"写代码"。</p><h2 id=为什么要自己实现一个代码模型>为什么要自己实现一个代码模型？</h2><p>市面上已经有很多优秀的代码生成模型，但自己动手实现一个有几个独特的价值：</p><ol><li><strong>深入理解原理</strong>：纸上得来终觉浅，只有亲手实现才能真正理解每个组件的作用</li><li><strong>定制化需求</strong>：你可以针对特定的代码风格或领域进行优化</li><li><strong>资源可控</strong>：小模型可以在消费级 GPU 上训练和运行</li><li><strong>学习路径</strong>：这是进入 AI 领域的绝佳实践项目</li></ol><p>我们的目标是训练一个约 50M 参数的模型，能够：</p><ul><li>根据函数签名和注释生成 Python 函数体</li><li>补全未完成的代码片段</li><li>理解基本的 Python 语法和常用库</li></ul><h2 id=整体架构概览>整体架构概览</h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>┌─────────────────────────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│                    Code Generation LLM                       │
</span></span><span class=line><span class=cl>├─────────────────────────────────────────────────────────────┤
</span></span><span class=line><span class=cl>│  1. 数据收集与预处理                                          │
</span></span><span class=line><span class=cl>│     └── Python 代码语料库 → 清洗 → Tokenization              │
</span></span><span class=line><span class=cl>├─────────────────────────────────────────────────────────────┤
</span></span><span class=line><span class=cl>│  2. 模型架构                                                  │
</span></span><span class=line><span class=cl>│     └── Decoder-only Transformer (GPT-style)                 │
</span></span><span class=line><span class=cl>├─────────────────────────────────────────────────────────────┤
</span></span><span class=line><span class=cl>│  3. 训练流程                                                  │
</span></span><span class=line><span class=cl>│     └── Next Token Prediction + Causal Language Modeling     │
</span></span><span class=line><span class=cl>├─────────────────────────────────────────────────────────────┤
</span></span><span class=line><span class=cl>│  4. 推理与代码生成                                            │
</span></span><span class=line><span class=cl>│     └── Temperature Sampling + Top-k/Top-p                   │
</span></span><span class=line><span class=cl>└─────────────────────────────────────────────────────────────┘
</span></span></code></pre></div><h2 id=step-1-数据收集与预处理>Step 1: 数据收集与预处理</h2><h3 id=11-收集-python-代码数据>1.1 收集 Python 代码数据</h3><p>高质量的训练数据是模型成功的基础。我们可以从以下来源获取 Python 代码：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>ast</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>List</span><span class=p>,</span> <span class=n>Optional</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>dataclasses</span> <span class=kn>import</span> <span class=n>dataclass</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@dataclass</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>CodeSample</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;表示一个代码样本&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>source</span><span class=p>:</span> <span class=nb>str</span>           <span class=c1># 原始代码</span>
</span></span><span class=line><span class=cl>    <span class=n>file_path</span><span class=p>:</span> <span class=nb>str</span>        <span class=c1># 文件路径</span>
</span></span><span class=line><span class=cl>    <span class=n>is_valid</span><span class=p>:</span> <span class=nb>bool</span>        <span class=c1># 是否语法正确</span>
</span></span><span class=line><span class=cl>    <span class=n>functions</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]</span>  <span class=c1># 提取的函数列表</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>collect_python_files</span><span class=p>(</span><span class=n>root_dir</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=n>Path</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    递归收集目录下所有 Python 文件
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        root_dir: 根目录路径
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        Python 文件路径列表
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>python_files</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>path</span> <span class=ow>in</span> <span class=n>Path</span><span class=p>(</span><span class=n>root_dir</span><span class=p>)</span><span class=o>.</span><span class=n>rglob</span><span class=p>(</span><span class=s2>&#34;*.py&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 跳过测试文件和虚拟环境</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=s2>&#34;test&#34;</span> <span class=ow>not</span> <span class=ow>in</span> <span class=nb>str</span><span class=p>(</span><span class=n>path</span><span class=p>)</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span> <span class=ow>and</span> <span class=s2>&#34;venv&#34;</span> <span class=ow>not</span> <span class=ow>in</span> <span class=nb>str</span><span class=p>(</span><span class=n>path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>python_files</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>python_files</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>validate_python_syntax</span><span class=p>(</span><span class=n>code</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>bool</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    检查代码是否是有效的 Python 语法
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        code: Python 代码字符串
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        语法是否有效
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>ast</span><span class=o>.</span><span class=n>parse</span><span class=p>(</span><span class=n>code</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>SyntaxError</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>extract_functions</span><span class=p>(</span><span class=n>code</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    从代码中提取所有函数定义
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        code: Python 代码字符串
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        函数代码列表
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>functions</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>tree</span> <span class=o>=</span> <span class=n>ast</span><span class=o>.</span><span class=n>parse</span><span class=p>(</span><span class=n>code</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>node</span> <span class=ow>in</span> <span class=n>ast</span><span class=o>.</span><span class=n>walk</span><span class=p>(</span><span class=n>tree</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>node</span><span class=p>,</span> <span class=n>ast</span><span class=o>.</span><span class=n>FunctionDef</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=c1># 获取函数的源代码</span>
</span></span><span class=line><span class=cl>                <span class=n>func_source</span> <span class=o>=</span> <span class=n>ast</span><span class=o>.</span><span class=n>get_source_segment</span><span class=p>(</span><span class=n>code</span><span class=p>,</span> <span class=n>node</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>func_source</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>functions</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>func_source</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>SyntaxError</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>pass</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>functions</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>process_code_file</span><span class=p>(</span><span class=n>file_path</span><span class=p>:</span> <span class=n>Path</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Optional</span><span class=p>[</span><span class=n>CodeSample</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    处理单个代码文件
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        file_path: 文件路径
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        CodeSample 对象或 None
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>file_path</span><span class=p>,</span> <span class=s1>&#39;r&#39;</span><span class=p>,</span> <span class=n>encoding</span><span class=o>=</span><span class=s1>&#39;utf-8&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>code</span> <span class=o>=</span> <span class=n>f</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 跳过过短或过长的文件</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>code</span><span class=p>)</span> <span class=o>&lt;</span> <span class=mi>100</span> <span class=ow>or</span> <span class=nb>len</span><span class=p>(</span><span class=n>code</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>100000</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>is_valid</span> <span class=o>=</span> <span class=n>validate_python_syntax</span><span class=p>(</span><span class=n>code</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>functions</span> <span class=o>=</span> <span class=n>extract_functions</span><span class=p>(</span><span class=n>code</span><span class=p>)</span> <span class=k>if</span> <span class=n>is_valid</span> <span class=k>else</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>CodeSample</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>source</span><span class=o>=</span><span class=n>code</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>file_path</span><span class=o>=</span><span class=nb>str</span><span class=p>(</span><span class=n>file_path</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>is_valid</span><span class=o>=</span><span class=n>is_valid</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>functions</span><span class=o>=</span><span class=n>functions</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>Exception</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># generated by hugo&#39;s coding agent</span>
</span></span></code></pre></div><h3 id=12-代码-tokenizer>1.2 代码 Tokenizer</h3><p>代码的 tokenization 与自然语言有所不同。我们需要保留缩进、特殊符号等对代码语义至关重要的信息。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>collections</span> <span class=kn>import</span> <span class=n>Counter</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>Dict</span><span class=p>,</span> <span class=n>List</span><span class=p>,</span> <span class=n>Tuple</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>CodeTokenizer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    专为 Python 代码设计的 Tokenizer
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    使用 Byte-Pair Encoding (BPE) 算法，但对代码特殊处理：
</span></span></span><span class=line><span class=cl><span class=s2>    - 保留缩进信息
</span></span></span><span class=line><span class=cl><span class=s2>    - 识别关键字和运算符
</span></span></span><span class=line><span class=cl><span class=s2>    - 处理字符串和注释
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Python 关键字作为特殊 token</span>
</span></span><span class=line><span class=cl>    <span class=n>PYTHON_KEYWORDS</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;def&#39;</span><span class=p>,</span> <span class=s1>&#39;class&#39;</span><span class=p>,</span> <span class=s1>&#39;if&#39;</span><span class=p>,</span> <span class=s1>&#39;else&#39;</span><span class=p>,</span> <span class=s1>&#39;elif&#39;</span><span class=p>,</span> <span class=s1>&#39;for&#39;</span><span class=p>,</span> <span class=s1>&#39;while&#39;</span><span class=p>,</span> <span class=s1>&#39;try&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;except&#39;</span><span class=p>,</span> <span class=s1>&#39;finally&#39;</span><span class=p>,</span> <span class=s1>&#39;with&#39;</span><span class=p>,</span> <span class=s1>&#39;as&#39;</span><span class=p>,</span> <span class=s1>&#39;import&#39;</span><span class=p>,</span> <span class=s1>&#39;from&#39;</span><span class=p>,</span> <span class=s1>&#39;return&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;yield&#39;</span><span class=p>,</span> <span class=s1>&#39;raise&#39;</span><span class=p>,</span> <span class=s1>&#39;pass&#39;</span><span class=p>,</span> <span class=s1>&#39;break&#39;</span><span class=p>,</span> <span class=s1>&#39;continue&#39;</span><span class=p>,</span> <span class=s1>&#39;lambda&#39;</span><span class=p>,</span> <span class=s1>&#39;and&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;or&#39;</span><span class=p>,</span> <span class=s1>&#39;not&#39;</span><span class=p>,</span> <span class=s1>&#39;in&#39;</span><span class=p>,</span> <span class=s1>&#39;is&#39;</span><span class=p>,</span> <span class=s1>&#39;None&#39;</span><span class=p>,</span> <span class=s1>&#39;True&#39;</span><span class=p>,</span> <span class=s1>&#39;False&#39;</span><span class=p>,</span> <span class=s1>&#39;async&#39;</span><span class=p>,</span> <span class=s1>&#39;await&#39;</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 特殊 token</span>
</span></span><span class=line><span class=cl>    <span class=n>SPECIAL_TOKENS</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;&lt;PAD&gt;&#39;</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;&lt;UNK&gt;&#39;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;&lt;BOS&gt;&#39;</span><span class=p>:</span> <span class=mi>2</span><span class=p>,</span>  <span class=c1># Beginning of sequence</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;&lt;EOS&gt;&#39;</span><span class=p>:</span> <span class=mi>3</span><span class=p>,</span>  <span class=c1># End of sequence</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;&lt;INDENT&gt;&#39;</span><span class=p>:</span> <span class=mi>4</span><span class=p>,</span>  <span class=c1># 缩进增加</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;&lt;DEDENT&gt;&#39;</span><span class=p>:</span> <span class=mi>5</span><span class=p>,</span>  <span class=c1># 缩进减少</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;&lt;NEWLINE&gt;&#39;</span><span class=p>:</span> <span class=mi>6</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>8000</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>vocab_size</span> <span class=o>=</span> <span class=n>vocab_size</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>token_to_id</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>int</span><span class=p>]</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>id_to_token</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>int</span><span class=p>,</span> <span class=nb>str</span><span class=p>]</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>merges</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=n>Tuple</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>str</span><span class=p>],</span> <span class=nb>str</span><span class=p>]</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_pre_tokenize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>code</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        预分词：将代码分割成基本单元
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        处理策略：
</span></span></span><span class=line><span class=cl><span class=s2>        1. 保留完整的字符串
</span></span></span><span class=line><span class=cl><span class=s2>        2. 分离运算符和标点
</span></span></span><span class=line><span class=cl><span class=s2>        3. 保留空白用于缩进处理
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>tokens</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 正则表达式匹配不同类型的 token</span>
</span></span><span class=line><span class=cl>        <span class=n>pattern</span> <span class=o>=</span> <span class=sa>r</span><span class=s1>&#39;&#39;&#39;
</span></span></span><span class=line><span class=cl><span class=s1>            (&#34;[^&#34;]*&#34;|&#39;[^&#39;]*&#39;)  |  # 字符串
</span></span></span><span class=line><span class=cl><span class=s1>            (\#[^\n]*)         |  # 注释
</span></span></span><span class=line><span class=cl><span class=s1>            (\d+\.?\d*)        |  # 数字
</span></span></span><span class=line><span class=cl><span class=s1>            ([a-zA-Z_]\w*)     |  # 标识符
</span></span></span><span class=line><span class=cl><span class=s1>            ([ ]</span><span class=si>{4}</span><span class=s1>|\t)        |  # 缩进单位
</span></span></span><span class=line><span class=cl><span class=s1>            (\n)               |  # 换行
</span></span></span><span class=line><span class=cl><span class=s1>            ([^\s\w])             # 其他符号
</span></span></span><span class=line><span class=cl><span class=s1>        &#39;&#39;&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=k>match</span> <span class=ow>in</span> <span class=n>re</span><span class=o>.</span><span class=n>finditer</span><span class=p>(</span><span class=n>pattern</span><span class=p>,</span> <span class=n>code</span><span class=p>,</span> <span class=n>re</span><span class=o>.</span><span class=n>VERBOSE</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>token</span> <span class=o>=</span> <span class=k>match</span><span class=o>.</span><span class=n>group</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>token</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span> <span class=ow>or</span> <span class=n>token</span> <span class=ow>in</span> <span class=p>(</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>,</span> <span class=s1>&#39;    &#39;</span><span class=p>,</span> <span class=s1>&#39;</span><span class=se>\t</span><span class=s1>&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=n>tokens</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>token</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>tokens</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_process_indentation</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tokens</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        处理缩进，转换为 INDENT/DEDENT token
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>processed</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>indent_stack</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>current_indent</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>at_line_start</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>token</span> <span class=ow>in</span> <span class=n>tokens</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>token</span> <span class=o>==</span> <span class=s1>&#39;</span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>processed</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=s1>&#39;&lt;NEWLINE&gt;&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>at_line_start</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>                <span class=n>current_indent</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>            <span class=k>elif</span> <span class=n>at_line_start</span> <span class=ow>and</span> <span class=n>token</span> <span class=ow>in</span> <span class=p>(</span><span class=s1>&#39;    &#39;</span><span class=p>,</span> <span class=s1>&#39;</span><span class=se>\t</span><span class=s1>&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=n>current_indent</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>            <span class=k>elif</span> <span class=n>at_line_start</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=c1># 处理缩进变化</span>
</span></span><span class=line><span class=cl>                <span class=k>while</span> <span class=n>current_indent</span> <span class=o>&lt;</span> <span class=n>indent_stack</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>                    <span class=n>processed</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=s1>&#39;&lt;DEDENT&gt;&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>indent_stack</span><span class=o>.</span><span class=n>pop</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>current_indent</span> <span class=o>&gt;</span> <span class=n>indent_stack</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>                    <span class=n>processed</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=s1>&#39;&lt;INDENT&gt;&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>indent_stack</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>current_indent</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>at_line_start</span> <span class=o>=</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl>                <span class=n>processed</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>token</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>processed</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>token</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>processed</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>train</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>code_samples</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>],</span> <span class=n>num_merges</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>5000</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        训练 BPE tokenizer
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        Args:
</span></span></span><span class=line><span class=cl><span class=s2>            code_samples: 代码样本列表
</span></span></span><span class=line><span class=cl><span class=s2>            num_merges: BPE 合并次数
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># 初始化词表</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>token_to_id</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>SPECIAL_TOKENS</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>next_id</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>SPECIAL_TOKENS</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 添加 Python 关键字</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>keyword</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>PYTHON_KEYWORDS</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>token_to_id</span><span class=p>[</span><span class=n>keyword</span><span class=p>]</span> <span class=o>=</span> <span class=n>next_id</span>
</span></span><span class=line><span class=cl>            <span class=n>next_id</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 统计所有字符</span>
</span></span><span class=line><span class=cl>        <span class=n>all_tokens</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>code</span> <span class=ow>in</span> <span class=n>code_samples</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>tokens</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_pre_tokenize</span><span class=p>(</span><span class=n>code</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>tokens</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_process_indentation</span><span class=p>(</span><span class=n>tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>all_tokens</span><span class=o>.</span><span class=n>extend</span><span class=p>(</span><span class=n>tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 将每个 token 拆分成字符</span>
</span></span><span class=line><span class=cl>        <span class=n>words</span> <span class=o>=</span> <span class=p>[</span><span class=nb>list</span><span class=p>(</span><span class=n>t</span><span class=p>)</span> <span class=o>+</span> <span class=p>[</span><span class=s1>&#39;&lt;/w&gt;&#39;</span><span class=p>]</span> <span class=k>for</span> <span class=n>t</span> <span class=ow>in</span> <span class=n>all_tokens</span> <span class=k>if</span> <span class=n>t</span> <span class=ow>not</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>SPECIAL_TOKENS</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># BPE 训练</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_merges</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>pairs</span> <span class=o>=</span> <span class=n>Counter</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>words</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>word</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                    <span class=n>pairs</span><span class=p>[(</span><span class=n>word</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>word</span><span class=p>[</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>])]</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=ow>not</span> <span class=n>pairs</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>break</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>best_pair</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>pairs</span><span class=p>,</span> <span class=n>key</span><span class=o>=</span><span class=n>pairs</span><span class=o>.</span><span class=n>get</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>new_token</span> <span class=o>=</span> <span class=s1>&#39;&#39;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>best_pair</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>new_token</span> <span class=ow>not</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>token_to_id</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>token_to_id</span><span class=p>[</span><span class=n>new_token</span><span class=p>]</span> <span class=o>=</span> <span class=n>next_id</span>
</span></span><span class=line><span class=cl>                <span class=n>next_id</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>merges</span><span class=p>[</span><span class=n>best_pair</span><span class=p>]</span> <span class=o>=</span> <span class=n>new_token</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 应用合并</span>
</span></span><span class=line><span class=cl>            <span class=n>new_words</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>words</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>new_word</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>                <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>                <span class=k>while</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=nb>len</span><span class=p>(</span><span class=n>word</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                    <span class=k>if</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=nb>len</span><span class=p>(</span><span class=n>word</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span> <span class=ow>and</span> <span class=p>(</span><span class=n>word</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>word</span><span class=p>[</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>])</span> <span class=o>==</span> <span class=n>best_pair</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>new_word</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>new_token</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=n>i</span> <span class=o>+=</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>                    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>new_word</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>word</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
</span></span><span class=line><span class=cl>                        <span class=n>i</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>                <span class=n>new_words</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>new_word</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>words</span> <span class=o>=</span> <span class=n>new_words</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 构建反向映射</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>id_to_token</span> <span class=o>=</span> <span class=p>{</span><span class=n>v</span><span class=p>:</span> <span class=n>k</span> <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>token_to_id</span><span class=o>.</span><span class=n>items</span><span class=p>()}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>encode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>code</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=nb>int</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;将代码编码为 token ID 序列&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>tokens</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_pre_tokenize</span><span class=p>(</span><span class=n>code</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>tokens</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_process_indentation</span><span class=p>(</span><span class=n>tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>ids</span> <span class=o>=</span> <span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>SPECIAL_TOKENS</span><span class=p>[</span><span class=s1>&#39;&lt;BOS&gt;&#39;</span><span class=p>]]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>token</span> <span class=ow>in</span> <span class=n>tokens</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>token</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>token_to_id</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>token_to_id</span><span class=p>[</span><span class=n>token</span><span class=p>])</span>
</span></span><span class=line><span class=cl>            <span class=k>elif</span> <span class=n>token</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>SPECIAL_TOKENS</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>SPECIAL_TOKENS</span><span class=p>[</span><span class=n>token</span><span class=p>])</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=c1># 应用 BPE</span>
</span></span><span class=line><span class=cl>                <span class=n>word</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>token</span><span class=p>)</span> <span class=o>+</span> <span class=p>[</span><span class=s1>&#39;&lt;/w&gt;&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=k>while</span> <span class=nb>len</span><span class=p>(</span><span class=n>word</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>1</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>pairs</span> <span class=o>=</span> <span class=p>[(</span><span class=n>word</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>word</span><span class=p>[</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>])</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>word</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>                    <span class=n>mergeable</span> <span class=o>=</span> <span class=p>[</span><span class=n>p</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>pairs</span> <span class=k>if</span> <span class=n>p</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>merges</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                    <span class=k>if</span> <span class=ow>not</span> <span class=n>mergeable</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=k>break</span>
</span></span><span class=line><span class=cl>                    <span class=n>pair</span> <span class=o>=</span> <span class=nb>min</span><span class=p>(</span><span class=n>mergeable</span><span class=p>,</span> <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>p</span><span class=p>:</span> <span class=nb>list</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>merges</span><span class=o>.</span><span class=n>keys</span><span class=p>())</span><span class=o>.</span><span class=n>index</span><span class=p>(</span><span class=n>p</span><span class=p>))</span>
</span></span><span class=line><span class=cl>                    <span class=n>new_word</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>                    <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>                    <span class=k>while</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=nb>len</span><span class=p>(</span><span class=n>word</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                        <span class=k>if</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=nb>len</span><span class=p>(</span><span class=n>word</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span> <span class=ow>and</span> <span class=p>(</span><span class=n>word</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>word</span><span class=p>[</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>])</span> <span class=o>==</span> <span class=n>pair</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                            <span class=n>new_word</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>merges</span><span class=p>[</span><span class=n>pair</span><span class=p>])</span>
</span></span><span class=line><span class=cl>                            <span class=n>i</span> <span class=o>+=</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>                        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                            <span class=n>new_word</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>word</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
</span></span><span class=line><span class=cl>                            <span class=n>i</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>                    <span class=n>word</span> <span class=o>=</span> <span class=n>new_word</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=k>for</span> <span class=n>subtoken</span> <span class=ow>in</span> <span class=n>word</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=k>if</span> <span class=n>subtoken</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>token_to_id</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>token_to_id</span><span class=p>[</span><span class=n>subtoken</span><span class=p>])</span>
</span></span><span class=line><span class=cl>                    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>SPECIAL_TOKENS</span><span class=p>[</span><span class=s1>&#39;&lt;UNK&gt;&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>SPECIAL_TOKENS</span><span class=p>[</span><span class=s1>&#39;&lt;EOS&gt;&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>ids</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>decode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>ids</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>int</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;将 token ID 序列解码为代码&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>tokens</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=nb>id</span> <span class=ow>in</span> <span class=n>ids</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nb>id</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>id_to_token</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>token</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>id_to_token</span><span class=p>[</span><span class=nb>id</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>token</span> <span class=ow>not</span> <span class=ow>in</span> <span class=p>(</span><span class=s1>&#39;&lt;PAD&gt;&#39;</span><span class=p>,</span> <span class=s1>&#39;&lt;BOS&gt;&#39;</span><span class=p>,</span> <span class=s1>&#39;&lt;EOS&gt;&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                    <span class=n>tokens</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>token</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 重建代码</span>
</span></span><span class=line><span class=cl>        <span class=n>code</span> <span class=o>=</span> <span class=s1>&#39;&#39;</span>
</span></span><span class=line><span class=cl>        <span class=n>indent_level</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>token</span> <span class=ow>in</span> <span class=n>tokens</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>token</span> <span class=o>==</span> <span class=s1>&#39;&lt;NEWLINE&gt;&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>code</span> <span class=o>+=</span> <span class=s1>&#39;</span><span class=se>\n</span><span class=s1>&#39;</span> <span class=o>+</span> <span class=s1>&#39;    &#39;</span> <span class=o>*</span> <span class=n>indent_level</span>
</span></span><span class=line><span class=cl>            <span class=k>elif</span> <span class=n>token</span> <span class=o>==</span> <span class=s1>&#39;&lt;INDENT&gt;&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>indent_level</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>                <span class=n>code</span> <span class=o>+=</span> <span class=s1>&#39;    &#39;</span>
</span></span><span class=line><span class=cl>            <span class=k>elif</span> <span class=n>token</span> <span class=o>==</span> <span class=s1>&#39;&lt;DEDENT&gt;&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>indent_level</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>indent_level</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>code</span> <span class=o>=</span> <span class=n>code</span><span class=o>.</span><span class=n>rstrip</span><span class=p>(</span><span class=s1>&#39;    &#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>token</span> <span class=o>=</span> <span class=n>token</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s1>&#39;&lt;/w&gt;&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>code</span> <span class=o>+=</span> <span class=n>token</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>code</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># generated by hugo&#39;s coding agent</span>
</span></span></code></pre></div><h2 id=step-2-构建-transformer-模型>Step 2: 构建 Transformer 模型</h2><h3 id=21-模型配置>2.1 模型配置</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>dataclasses</span> <span class=kn>import</span> <span class=n>dataclass</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@dataclass</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>CodeLLMConfig</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;模型配置&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>vocab_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>8000</span>       <span class=c1># 词表大小</span>
</span></span><span class=line><span class=cl>    <span class=n>max_seq_len</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>1024</span>      <span class=c1># 最大序列长度</span>
</span></span><span class=line><span class=cl>    <span class=n>d_model</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>512</span>           <span class=c1># 模型维度</span>
</span></span><span class=line><span class=cl>    <span class=n>n_heads</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>8</span>             <span class=c1># 注意力头数</span>
</span></span><span class=line><span class=cl>    <span class=n>n_layers</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>6</span>            <span class=c1># Transformer 层数</span>
</span></span><span class=line><span class=cl>    <span class=n>d_ff</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>2048</span>             <span class=c1># 前馈网络维度</span>
</span></span><span class=line><span class=cl>    <span class=n>dropout</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.1</span>         <span class=c1># Dropout 概率</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@property</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>n_params</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>int</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;估算参数量&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># Embedding</span>
</span></span><span class=line><span class=cl>        <span class=n>embed_params</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>vocab_size</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>d_model</span>
</span></span><span class=line><span class=cl>        <span class=c1># Attention (Q, K, V, O projections per layer)</span>
</span></span><span class=line><span class=cl>        <span class=n>attn_params</span> <span class=o>=</span> <span class=mi>4</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>d_model</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>d_model</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_layers</span>
</span></span><span class=line><span class=cl>        <span class=c1># FFN (2 linear layers per layer)</span>
</span></span><span class=line><span class=cl>        <span class=n>ffn_params</span> <span class=o>=</span> <span class=mi>2</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>d_model</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>d_ff</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_layers</span>
</span></span><span class=line><span class=cl>        <span class=c1># Layer norms</span>
</span></span><span class=line><span class=cl>        <span class=n>ln_params</span> <span class=o>=</span> <span class=mi>4</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>d_model</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_layers</span>
</span></span><span class=line><span class=cl>        <span class=c1># Output projection</span>
</span></span><span class=line><span class=cl>        <span class=n>out_params</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>d_model</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>vocab_size</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>embed_params</span> <span class=o>+</span> <span class=n>attn_params</span> <span class=o>+</span> <span class=n>ffn_params</span> <span class=o>+</span> <span class=n>ln_params</span> <span class=o>+</span> <span class=n>out_params</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 50M 参数的配置</span>
</span></span><span class=line><span class=cl><span class=n>config</span> <span class=o>=</span> <span class=n>CodeLLMConfig</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Estimated parameters: </span><span class=si>{</span><span class=n>config</span><span class=o>.</span><span class=n>n_params</span> <span class=o>/</span> <span class=mf>1e6</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>M&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># Output: Estimated parameters: 51.2M</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># generated by hugo&#39;s coding agent</span>
</span></span></code></pre></div><h3 id=22-核心组件实现>2.2 核心组件实现</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>math</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn.functional</span> <span class=k>as</span> <span class=nn>F</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>Optional</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>RotaryPositionalEmbedding</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    旋转位置编码 (RoPE)
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    相比传统的正弦位置编码，RoPE 有更好的长度外推能力，
</span></span></span><span class=line><span class=cl><span class=s2>    且能更好地编码相对位置信息。
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>d_model</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span> <span class=n>max_seq_len</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>2048</span><span class=p>,</span> <span class=n>base</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>10000.0</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>d_model</span> <span class=o>=</span> <span class=n>d_model</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>max_seq_len</span> <span class=o>=</span> <span class=n>max_seq_len</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 计算频率</span>
</span></span><span class=line><span class=cl>        <span class=n>inv_freq</span> <span class=o>=</span> <span class=mf>1.0</span> <span class=o>/</span> <span class=p>(</span><span class=n>base</span> <span class=o>**</span> <span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>d_model</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>float</span><span class=p>()</span> <span class=o>/</span> <span class=n>d_model</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>register_buffer</span><span class=p>(</span><span class=s1>&#39;inv_freq&#39;</span><span class=p>,</span> <span class=n>inv_freq</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 预计算 cos 和 sin</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_build_cache</span><span class=p>(</span><span class=n>max_seq_len</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_build_cache</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>t</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>seq_len</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>inv_freq</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>freqs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;i,j-&gt;ij&#39;</span><span class=p>,</span> <span class=n>t</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>inv_freq</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>emb</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>freqs</span><span class=p>,</span> <span class=n>freqs</span><span class=p>],</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>register_buffer</span><span class=p>(</span><span class=s1>&#39;cos_cached&#39;</span><span class=p>,</span> <span class=n>emb</span><span class=o>.</span><span class=n>cos</span><span class=p>())</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>register_buffer</span><span class=p>(</span><span class=s1>&#39;sin_cached&#39;</span><span class=p>,</span> <span class=n>emb</span><span class=o>.</span><span class=n>sin</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>seq_len</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>seq_len</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>max_seq_len</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>_build_cache</span><span class=p>(</span><span class=n>seq_len</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>cos_cached</span><span class=p>[:</span><span class=n>seq_len</span><span class=p>],</span> <span class=bp>self</span><span class=o>.</span><span class=n>sin_cached</span><span class=p>[:</span><span class=n>seq_len</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>rotate_half</span><span class=p>(</span><span class=n>x</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;将张量的后半部分旋转到前面并取负&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>x1</span><span class=p>,</span> <span class=n>x2</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=p>:</span><span class=n>x</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>//</span><span class=mi>2</span><span class=p>],</span> <span class=n>x</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=n>x</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>//</span><span class=mi>2</span><span class=p>:]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=o>-</span><span class=n>x2</span><span class=p>,</span> <span class=n>x1</span><span class=p>],</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>apply_rotary_pos_emb</span><span class=p>(</span><span class=n>q</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span> <span class=n>k</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                         <span class=n>cos</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span> <span class=n>sin</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>tuple</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;应用旋转位置编码到 Q 和 K&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>q_embed</span> <span class=o>=</span> <span class=p>(</span><span class=n>q</span> <span class=o>*</span> <span class=n>cos</span><span class=p>)</span> <span class=o>+</span> <span class=p>(</span><span class=n>rotate_half</span><span class=p>(</span><span class=n>q</span><span class=p>)</span> <span class=o>*</span> <span class=n>sin</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>k_embed</span> <span class=o>=</span> <span class=p>(</span><span class=n>k</span> <span class=o>*</span> <span class=n>cos</span><span class=p>)</span> <span class=o>+</span> <span class=p>(</span><span class=n>rotate_half</span><span class=p>(</span><span class=n>k</span><span class=p>)</span> <span class=o>*</span> <span class=n>sin</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>q_embed</span><span class=p>,</span> <span class=n>k_embed</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>MultiHeadAttention</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    多头自注意力机制
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    使用 RoPE 位置编码和 KV Cache 优化推理速度
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>:</span> <span class=n>CodeLLMConfig</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>n_heads</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>d_model</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>d_model</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>head_dim</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>d_model</span> <span class=o>//</span> <span class=n>config</span><span class=o>.</span><span class=n>n_heads</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>assert</span> <span class=bp>self</span><span class=o>.</span><span class=n>head_dim</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span> <span class=o>==</span> <span class=n>config</span><span class=o>.</span><span class=n>d_model</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>q_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>d_model</span><span class=p>,</span> <span class=n>config</span><span class=o>.</span><span class=n>d_model</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>k_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>d_model</span><span class=p>,</span> <span class=n>config</span><span class=o>.</span><span class=n>d_model</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>v_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>d_model</span><span class=p>,</span> <span class=n>config</span><span class=o>.</span><span class=n>d_model</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>o_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>d_model</span><span class=p>,</span> <span class=n>config</span><span class=o>.</span><span class=n>d_model</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>dropout</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>rope</span> <span class=o>=</span> <span class=n>RotaryPositionalEmbedding</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>head_dim</span><span class=p>,</span> <span class=n>config</span><span class=o>.</span><span class=n>max_seq_len</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>mask</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>kv_cache</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=nb>tuple</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>tuple</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_size</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 线性投影</span>
</span></span><span class=line><span class=cl>        <span class=n>q</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>q_proj</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>k</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>k_proj</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>v</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>v_proj</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 重塑为多头</span>
</span></span><span class=line><span class=cl>        <span class=n>q</span> <span class=o>=</span> <span class=n>q</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>head_dim</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>k</span> <span class=o>=</span> <span class=n>k</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>head_dim</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>v</span> <span class=o>=</span> <span class=n>v</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>head_dim</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 应用 RoPE</span>
</span></span><span class=line><span class=cl>        <span class=n>cos</span><span class=p>,</span> <span class=n>sin</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>rope</span><span class=p>(</span><span class=n>q</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>q</span><span class=p>,</span> <span class=n>k</span> <span class=o>=</span> <span class=n>apply_rotary_pos_emb</span><span class=p>(</span><span class=n>q</span><span class=p>,</span> <span class=n>k</span><span class=p>,</span> <span class=n>cos</span><span class=p>,</span> <span class=n>sin</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># KV Cache 处理</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>kv_cache</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>k_cache</span><span class=p>,</span> <span class=n>v_cache</span> <span class=o>=</span> <span class=n>kv_cache</span>
</span></span><span class=line><span class=cl>            <span class=n>k</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>k_cache</span><span class=p>,</span> <span class=n>k</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>v</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>v_cache</span><span class=p>,</span> <span class=n>v</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>new_kv_cache</span> <span class=o>=</span> <span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>v</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 计算注意力分数</span>
</span></span><span class=line><span class=cl>        <span class=n>scale</span> <span class=o>=</span> <span class=n>math</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>head_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>attn_scores</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>q</span><span class=p>,</span> <span class=n>k</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>))</span> <span class=o>/</span> <span class=n>scale</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 应用因果掩码</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>mask</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>attn_scores</span> <span class=o>=</span> <span class=n>attn_scores</span><span class=o>.</span><span class=n>masked_fill</span><span class=p>(</span><span class=n>mask</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=nb>float</span><span class=p>(</span><span class=s1>&#39;-inf&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>attn_probs</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>attn_scores</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>attn_probs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=n>attn_probs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 加权求和</span>
</span></span><span class=line><span class=cl>        <span class=n>attn_output</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>attn_probs</span><span class=p>,</span> <span class=n>v</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 重塑并投影</span>
</span></span><span class=line><span class=cl>        <span class=n>attn_output</span> <span class=o>=</span> <span class=n>attn_output</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>attn_output</span> <span class=o>=</span> <span class=n>attn_output</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>d_model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>o_proj</span><span class=p>(</span><span class=n>attn_output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>output</span><span class=p>,</span> <span class=n>new_kv_cache</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>FeedForward</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    前馈神经网络
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    使用 SwiGLU 激活函数，相比 ReLU 在语言模型中表现更好
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>:</span> <span class=n>CodeLLMConfig</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>gate_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>d_model</span><span class=p>,</span> <span class=n>config</span><span class=o>.</span><span class=n>d_ff</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>up_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>d_model</span><span class=p>,</span> <span class=n>config</span><span class=o>.</span><span class=n>d_ff</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>down_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>d_ff</span><span class=p>,</span> <span class=n>config</span><span class=o>.</span><span class=n>d_model</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>dropout</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># SwiGLU: gate * up</span>
</span></span><span class=line><span class=cl>        <span class=n>gate</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>silu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>gate_proj</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>up</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>up_proj</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>gate</span> <span class=o>*</span> <span class=n>up</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>down_proj</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>TransformerBlock</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    单个 Transformer 块
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    使用 Pre-LayerNorm 结构，训练更稳定
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>:</span> <span class=n>CodeLLMConfig</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>attention</span> <span class=o>=</span> <span class=n>MultiHeadAttention</span><span class=p>(</span><span class=n>config</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>feed_forward</span> <span class=o>=</span> <span class=n>FeedForward</span><span class=p>(</span><span class=n>config</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>ln1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>d_model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>ln2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>d_model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>mask</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>kv_cache</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=nb>tuple</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>tuple</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Self-attention with residual</span>
</span></span><span class=line><span class=cl>        <span class=n>normed</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ln1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>attn_out</span><span class=p>,</span> <span class=n>new_kv_cache</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>attention</span><span class=p>(</span><span class=n>normed</span><span class=p>,</span> <span class=n>mask</span><span class=p>,</span> <span class=n>kv_cache</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span> <span class=o>+</span> <span class=n>attn_out</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># FFN with residual</span>
</span></span><span class=line><span class=cl>        <span class=n>normed</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ln2</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ff_out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>feed_forward</span><span class=p>(</span><span class=n>normed</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span> <span class=o>+</span> <span class=n>ff_out</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span><span class=p>,</span> <span class=n>new_kv_cache</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># generated by hugo&#39;s coding agent</span>
</span></span></code></pre></div><h3 id=23-完整模型>2.3 完整模型</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>CodeLLM</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    代码生成语言模型
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Decoder-only Transformer 架构，专为 Python 代码生成优化
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>:</span> <span class=n>CodeLLMConfig</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>config</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Token embedding</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>embed_tokens</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>config</span><span class=o>.</span><span class=n>d_model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Transformer blocks</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>layers</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>([</span>
</span></span><span class=line><span class=cl>            <span class=n>TransformerBlock</span><span class=p>(</span><span class=n>config</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>n_layers</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 最终 LayerNorm</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>ln_f</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>d_model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 输出投影（与 embedding 共享权重）</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>lm_head</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>d_model</span><span class=p>,</span> <span class=n>config</span><span class=o>.</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>lm_head</span><span class=o>.</span><span class=n>weight</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>embed_tokens</span><span class=o>.</span><span class=n>weight</span>  <span class=c1># 权重共享</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 初始化权重</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_init_weights</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_init_weights</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Xavier/Glorot 初始化&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>module</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>xavier_uniform_</span><span class=p>(</span><span class=n>module</span><span class=o>.</span><span class=n>weight</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>module</span><span class=o>.</span><span class=n>bias</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>zeros_</span><span class=p>(</span><span class=n>module</span><span class=o>.</span><span class=n>bias</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>module</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>normal_</span><span class=p>(</span><span class=n>module</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span> <span class=n>std</span><span class=o>=</span><span class=mf>0.02</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_create_causal_mask</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span> <span class=n>device</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;创建因果注意力掩码&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>mask</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>triu</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=n>seq_len</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>),</span> <span class=n>diagonal</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>mask</span> <span class=o>=</span> <span class=n>mask</span><span class=o>.</span><span class=n>masked_fill</span><span class=p>(</span><span class=n>mask</span> <span class=o>==</span> <span class=mi>1</span><span class=p>,</span> <span class=nb>float</span><span class=p>(</span><span class=s1>&#39;-inf&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>mask</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>input_ids</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>labels</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>kv_cache</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=nb>list</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>dict</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        前向传播
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        Args:
</span></span></span><span class=line><span class=cl><span class=s2>            input_ids: 输入 token IDs [batch_size, seq_len]
</span></span></span><span class=line><span class=cl><span class=s2>            labels: 标签 [batch_size, seq_len]，用于计算损失
</span></span></span><span class=line><span class=cl><span class=s2>            kv_cache: KV 缓存，用于高效推理
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        Returns:
</span></span></span><span class=line><span class=cl><span class=s2>            包含 logits 和可选 loss 的字典
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_size</span><span class=p>,</span> <span class=n>seq_len</span> <span class=o>=</span> <span class=n>input_ids</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>        <span class=n>device</span> <span class=o>=</span> <span class=n>input_ids</span><span class=o>.</span><span class=n>device</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Token embedding</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>embed_tokens</span><span class=p>(</span><span class=n>input_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 创建因果掩码</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>kv_cache</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>mask</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_create_causal_mask</span><span class=p>(</span><span class=n>seq_len</span><span class=p>,</span> <span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>mask</span> <span class=o>=</span> <span class=kc>None</span>  <span class=c1># 使用 cache 时不需要完整掩码</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 通过 Transformer 层</span>
</span></span><span class=line><span class=cl>        <span class=n>new_kv_cache</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>layer</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>layers</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>layer_cache</span> <span class=o>=</span> <span class=n>kv_cache</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=k>if</span> <span class=n>kv_cache</span> <span class=k>else</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>            <span class=n>x</span><span class=p>,</span> <span class=n>layer_kv</span> <span class=o>=</span> <span class=n>layer</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>mask</span><span class=p>,</span> <span class=n>layer_cache</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>new_kv_cache</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>layer_kv</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 最终 LayerNorm</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ln_f</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 计算 logits</span>
</span></span><span class=line><span class=cl>        <span class=n>logits</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>lm_head</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 计算损失</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>labels</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>shift_logits</span> <span class=o>=</span> <span class=n>logits</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=p>:</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>shift_labels</span> <span class=o>=</span> <span class=n>labels</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=mi>1</span><span class=p>:]</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>cross_entropy</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>shift_logits</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>vocab_size</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>shift_labels</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>ignore_index</span><span class=o>=-</span><span class=mi>100</span>  <span class=c1># 忽略 padding</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;logits&#39;</span><span class=p>:</span> <span class=n>logits</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;loss&#39;</span><span class=p>:</span> <span class=n>loss</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;kv_cache&#39;</span><span class=p>:</span> <span class=n>new_kv_cache</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@torch.no_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>generate</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>input_ids</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>max_new_tokens</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>256</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>temperature</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.8</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>top_k</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>50</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>top_p</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.95</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>stop_tokens</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=nb>list</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        自回归生成代码
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        Args:
</span></span></span><span class=line><span class=cl><span class=s2>            input_ids: 输入 prompt 的 token IDs
</span></span></span><span class=line><span class=cl><span class=s2>            max_new_tokens: 最大生成 token 数
</span></span></span><span class=line><span class=cl><span class=s2>            temperature: 采样温度，越高越随机
</span></span></span><span class=line><span class=cl><span class=s2>            top_k: Top-k 采样
</span></span></span><span class=line><span class=cl><span class=s2>            top_p: Nucleus 采样
</span></span></span><span class=line><span class=cl><span class=s2>            stop_tokens: 停止 token 列表
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        Returns:
</span></span></span><span class=line><span class=cl><span class=s2>            生成的完整 token 序列
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>device</span> <span class=o>=</span> <span class=n>input_ids</span><span class=o>.</span><span class=n>device</span>
</span></span><span class=line><span class=cl>        <span class=n>generated</span> <span class=o>=</span> <span class=n>input_ids</span><span class=o>.</span><span class=n>clone</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>kv_cache</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>max_new_tokens</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=c1># 只使用新 token（如果有 cache）</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>kv_cache</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>curr_input</span> <span class=o>=</span> <span class=n>generated</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>:]</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>curr_input</span> <span class=o>=</span> <span class=n>generated</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 前向传播</span>
</span></span><span class=line><span class=cl>            <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>forward</span><span class=p>(</span><span class=n>curr_input</span><span class=p>,</span> <span class=n>kv_cache</span><span class=o>=</span><span class=n>kv_cache</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>logits</span> <span class=o>=</span> <span class=n>outputs</span><span class=p>[</span><span class=s1>&#39;logits&#39;</span><span class=p>][:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=p>:]</span>  <span class=c1># 最后一个位置</span>
</span></span><span class=line><span class=cl>            <span class=n>kv_cache</span> <span class=o>=</span> <span class=n>outputs</span><span class=p>[</span><span class=s1>&#39;kv_cache&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 应用温度</span>
</span></span><span class=line><span class=cl>            <span class=n>logits</span> <span class=o>=</span> <span class=n>logits</span> <span class=o>/</span> <span class=n>temperature</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Top-k 过滤</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>top_k</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>indices_to_remove</span> <span class=o>=</span> <span class=n>logits</span> <span class=o>&lt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>topk</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>top_k</span><span class=p>)[</span><span class=mi>0</span><span class=p>][</span><span class=o>...</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=kc>None</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=n>logits</span><span class=p>[</span><span class=n>indices_to_remove</span><span class=p>]</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=s1>&#39;-inf&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Top-p (nucleus) 过滤</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>top_p</span> <span class=o>&lt;</span> <span class=mf>1.0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>sorted_logits</span><span class=p>,</span> <span class=n>sorted_indices</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sort</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>descending</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>cumulative_probs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cumsum</span><span class=p>(</span><span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>sorted_logits</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>),</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=n>sorted_indices_to_remove</span> <span class=o>=</span> <span class=n>cumulative_probs</span> <span class=o>&gt;</span> <span class=n>top_p</span>
</span></span><span class=line><span class=cl>                <span class=n>sorted_indices_to_remove</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=mi>1</span><span class=p>:]</span> <span class=o>=</span> <span class=n>sorted_indices_to_remove</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=p>:</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>clone</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=n>sorted_indices_to_remove</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=n>indices_to_remove</span> <span class=o>=</span> <span class=n>sorted_indices_to_remove</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=mi>1</span><span class=p>,</span> <span class=n>sorted_indices</span><span class=p>,</span> <span class=n>sorted_indices_to_remove</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>logits</span><span class=p>[</span><span class=n>indices_to_remove</span><span class=p>]</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=s1>&#39;-inf&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 采样</span>
</span></span><span class=line><span class=cl>            <span class=n>probs</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>next_token</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>multinomial</span><span class=p>(</span><span class=n>probs</span><span class=p>,</span> <span class=n>num_samples</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 添加到生成序列</span>
</span></span><span class=line><span class=cl>            <span class=n>generated</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>generated</span><span class=p>,</span> <span class=n>next_token</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 检查停止条件</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>stop_tokens</span> <span class=ow>and</span> <span class=n>next_token</span><span class=o>.</span><span class=n>item</span><span class=p>()</span> <span class=ow>in</span> <span class=n>stop_tokens</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>break</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>generated</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># generated by hugo&#39;s coding agent</span>
</span></span></code></pre></div><h2 id=step-3-训练流程>Step 3: 训练流程</h2><h3 id=31-数据集>3.1 数据集</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.utils.data</span> <span class=kn>import</span> <span class=n>Dataset</span><span class=p>,</span> <span class=n>DataLoader</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>CodeDataset</span><span class=p>(</span><span class=n>Dataset</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;代码训练数据集&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>code_samples</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                 <span class=n>tokenizer</span><span class=p>:</span> <span class=n>CodeTokenizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>max_length</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>1024</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>tokenizer</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>max_length</span> <span class=o>=</span> <span class=n>max_length</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 预处理：tokenize 所有代码</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>examples</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>code</span> <span class=ow>in</span> <span class=n>code_samples</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>ids</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>code</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>ids</span><span class=p>)</span> <span class=o>&lt;=</span> <span class=n>max_length</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>examples</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=c1># 切分长序列</span>
</span></span><span class=line><span class=cl>                <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>ids</span><span class=p>)</span> <span class=o>-</span> <span class=n>max_length</span><span class=p>,</span> <span class=n>max_length</span> <span class=o>//</span> <span class=mi>2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                    <span class=bp>self</span><span class=o>.</span><span class=n>examples</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>ids</span><span class=p>[</span><span class=n>i</span><span class=p>:</span><span class=n>i</span> <span class=o>+</span> <span class=n>max_length</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__len__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>examples</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__getitem__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>idx</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>ids</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>examples</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Padding</span>
</span></span><span class=line><span class=cl>        <span class=n>padding_length</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>max_length</span> <span class=o>-</span> <span class=nb>len</span><span class=p>(</span><span class=n>ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>input_ids</span> <span class=o>=</span> <span class=n>ids</span> <span class=o>+</span> <span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>padding_length</span>  <span class=c1># 0 是 PAD token</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Labels: 与 input 相同，但 padding 位置设为 -100</span>
</span></span><span class=line><span class=cl>        <span class=n>labels</span> <span class=o>=</span> <span class=n>ids</span> <span class=o>+</span> <span class=p>[</span><span class=o>-</span><span class=mi>100</span><span class=p>]</span> <span class=o>*</span> <span class=n>padding_length</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;input_ids&#39;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>input_ids</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;labels&#39;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>labels</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>collate_fn</span><span class=p>(</span><span class=n>batch</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;批次整理函数&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>input_ids</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>([</span><span class=n>x</span><span class=p>[</span><span class=s1>&#39;input_ids&#39;</span><span class=p>]</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>batch</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>labels</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>([</span><span class=n>x</span><span class=p>[</span><span class=s1>&#39;labels&#39;</span><span class=p>]</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>batch</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span><span class=s1>&#39;input_ids&#39;</span><span class=p>:</span> <span class=n>input_ids</span><span class=p>,</span> <span class=s1>&#39;labels&#39;</span><span class=p>:</span> <span class=n>labels</span><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># generated by hugo&#39;s coding agent</span>
</span></span></code></pre></div><h3 id=32-训练器>3.2 训练器</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.optim</span> <span class=kn>import</span> <span class=n>AdamW</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.optim.lr_scheduler</span> <span class=kn>import</span> <span class=n>CosineAnnealingLR</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>tqdm</span> <span class=kn>import</span> <span class=n>tqdm</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>wandb</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>CodeLLMTrainer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;训练器&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>model</span><span class=p>:</span> <span class=n>CodeLLM</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>train_dataset</span><span class=p>:</span> <span class=n>CodeDataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>val_dataset</span><span class=p>:</span> <span class=n>CodeDataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>config</span><span class=p>:</span> <span class=nb>dict</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=n>model</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>train_dataset</span> <span class=o>=</span> <span class=n>train_dataset</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>val_dataset</span> <span class=o>=</span> <span class=n>val_dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 训练配置</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>batch_size</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;batch_size&#39;</span><span class=p>,</span> <span class=mi>32</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>learning_rate</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;learning_rate&#39;</span><span class=p>,</span> <span class=mf>3e-4</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>epochs</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;epochs&#39;</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>warmup_steps</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;warmup_steps&#39;</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>gradient_clip</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;gradient_clip&#39;</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>device</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;device&#39;</span><span class=p>,</span> <span class=s1>&#39;cuda&#39;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 移动模型到设备</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 优化器</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span> <span class=o>=</span> <span class=n>AdamW</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>lr</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>learning_rate</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>betas</span><span class=o>=</span><span class=p>(</span><span class=mf>0.9</span><span class=p>,</span> <span class=mf>0.95</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>weight_decay</span><span class=o>=</span><span class=mf>0.1</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 数据加载器</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>train_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>train_dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>batch_size</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>batch_size</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>collate_fn</span><span class=o>=</span><span class=n>collate_fn</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>num_workers</span><span class=o>=</span><span class=mi>4</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>val_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>val_dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>batch_size</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>batch_size</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>collate_fn</span><span class=o>=</span><span class=n>collate_fn</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>num_workers</span><span class=o>=</span><span class=mi>4</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 学习率调度器</span>
</span></span><span class=line><span class=cl>        <span class=n>total_steps</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>train_loader</span><span class=p>)</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>epochs</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>scheduler</span> <span class=o>=</span> <span class=n>CosineAnnealingLR</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>T_max</span><span class=o>=</span><span class=n>total_steps</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>eta_min</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>learning_rate</span> <span class=o>*</span> <span class=mf>0.1</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>train_epoch</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>epoch</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>float</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;训练一个 epoch&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>total_loss</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>progress_bar</span> <span class=o>=</span> <span class=n>tqdm</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>train_loader</span><span class=p>,</span> <span class=n>desc</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Epoch </span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>batch</span> <span class=ow>in</span> <span class=n>progress_bar</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>input_ids</span> <span class=o>=</span> <span class=n>batch</span><span class=p>[</span><span class=s1>&#39;input_ids&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>labels</span> <span class=o>=</span> <span class=n>batch</span><span class=p>[</span><span class=s1>&#39;labels&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 前向传播</span>
</span></span><span class=line><span class=cl>            <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>(</span><span class=n>input_ids</span><span class=p>,</span> <span class=n>labels</span><span class=o>=</span><span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span> <span class=o>=</span> <span class=n>outputs</span><span class=p>[</span><span class=s1>&#39;loss&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 反向传播</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 梯度裁剪</span>
</span></span><span class=line><span class=cl>            <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>clip_grad_norm_</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>gradient_clip</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>scheduler</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>total_loss</span> <span class=o>+=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>progress_bar</span><span class=o>.</span><span class=n>set_postfix</span><span class=p>({</span><span class=s1>&#39;loss&#39;</span><span class=p>:</span> <span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>total_loss</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>train_loader</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@torch.no_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>evaluate</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>float</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;评估模型&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>total_loss</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>batch</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>val_loader</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>input_ids</span> <span class=o>=</span> <span class=n>batch</span><span class=p>[</span><span class=s1>&#39;input_ids&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>labels</span> <span class=o>=</span> <span class=n>batch</span><span class=p>[</span><span class=s1>&#39;labels&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>(</span><span class=n>input_ids</span><span class=p>,</span> <span class=n>labels</span><span class=o>=</span><span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>total_loss</span> <span class=o>+=</span> <span class=n>outputs</span><span class=p>[</span><span class=s1>&#39;loss&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>total_loss</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>val_loader</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>train</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;完整训练流程&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>best_val_loss</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=s1>&#39;inf&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>epochs</span> <span class=o>+</span> <span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>train_loss</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>train_epoch</span><span class=p>(</span><span class=n>epoch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>val_loss</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>evaluate</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Epoch </span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s1>: Train Loss = </span><span class=si>{</span><span class=n>train_loss</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>, Val Loss = </span><span class=si>{</span><span class=n>val_loss</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 保存最佳模型</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>val_loss</span> <span class=o>&lt;</span> <span class=n>best_val_loss</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>best_val_loss</span> <span class=o>=</span> <span class=n>val_loss</span>
</span></span><span class=line><span class=cl>                <span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>({</span>
</span></span><span class=line><span class=cl>                    <span class=s1>&#39;epoch&#39;</span><span class=p>:</span> <span class=n>epoch</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=s1>&#39;model_state_dict&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                    <span class=s1>&#39;optimizer_state_dict&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                    <span class=s1>&#39;val_loss&#39;</span><span class=p>:</span> <span class=n>val_loss</span>
</span></span><span class=line><span class=cl>                <span class=p>},</span> <span class=s1>&#39;best_model.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;  -&gt; Saved best model (val_loss: </span><span class=si>{</span><span class=n>val_loss</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># generated by hugo&#39;s coding agent</span>
</span></span></code></pre></div><h3 id=33-开始训练>3.3 开始训练</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 完整的训练脚本</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>main</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=c1># 1. 收集数据</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Collecting Python code samples...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>python_files</span> <span class=o>=</span> <span class=n>collect_python_files</span><span class=p>(</span><span class=s2>&#34;/path/to/python/repos&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>code_samples</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>f</span> <span class=ow>in</span> <span class=n>tqdm</span><span class=p>(</span><span class=n>python_files</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>sample</span> <span class=o>=</span> <span class=n>process_code_file</span><span class=p>(</span><span class=n>f</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>sample</span> <span class=ow>and</span> <span class=n>sample</span><span class=o>.</span><span class=n>is_valid</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>code_samples</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>sample</span><span class=o>.</span><span class=n>source</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Collected </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>code_samples</span><span class=p>)</span><span class=si>}</span><span class=s2> valid Python files&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 2. 训练 tokenizer</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Training tokenizer...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenizer</span> <span class=o>=</span> <span class=n>CodeTokenizer</span><span class=p>(</span><span class=n>vocab_size</span><span class=o>=</span><span class=mi>8000</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenizer</span><span class=o>.</span><span class=n>train</span><span class=p>(</span><span class=n>code_samples</span><span class=p>[:</span><span class=mi>10000</span><span class=p>],</span> <span class=n>num_merges</span><span class=o>=</span><span class=mi>5000</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 3. 创建数据集</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Creating datasets...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>train_samples</span> <span class=o>=</span> <span class=n>code_samples</span><span class=p>[:</span><span class=nb>int</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>code_samples</span><span class=p>)</span> <span class=o>*</span> <span class=mf>0.9</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=n>val_samples</span> <span class=o>=</span> <span class=n>code_samples</span><span class=p>[</span><span class=nb>int</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>code_samples</span><span class=p>)</span> <span class=o>*</span> <span class=mf>0.9</span><span class=p>):]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>train_dataset</span> <span class=o>=</span> <span class=n>CodeDataset</span><span class=p>(</span><span class=n>train_samples</span><span class=p>,</span> <span class=n>tokenizer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>val_dataset</span> <span class=o>=</span> <span class=n>CodeDataset</span><span class=p>(</span><span class=n>val_samples</span><span class=p>,</span> <span class=n>tokenizer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Train: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>)</span><span class=si>}</span><span class=s2>, Val: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>val_dataset</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 4. 创建模型</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Initializing model...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>config</span> <span class=o>=</span> <span class=n>CodeLLMConfig</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>CodeLLM</span><span class=p>(</span><span class=n>config</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Model parameters: </span><span class=si>{</span><span class=nb>sum</span><span class=p>(</span><span class=n>p</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span> <span class=o>/</span> <span class=mf>1e6</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>M&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 5. 训练</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Starting training...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>trainer</span> <span class=o>=</span> <span class=n>CodeLLMTrainer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>train_dataset</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>val_dataset</span><span class=o>=</span><span class=n>val_dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>config</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;batch_size&#39;</span><span class=p>:</span> <span class=mi>32</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;learning_rate&#39;</span><span class=p>:</span> <span class=mf>3e-4</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;epochs&#39;</span><span class=p>:</span> <span class=mi>10</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;device&#39;</span><span class=p>:</span> <span class=s1>&#39;cuda&#39;</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>trainer</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>main</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># generated by hugo&#39;s coding agent</span>
</span></span></code></pre></div><h2 id=step-4-推理与代码生成>Step 4: 推理与代码生成</h2><p>训练完成后，让我们看看如何使用模型生成代码。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>generate_code</span><span class=p>(</span><span class=n>model</span><span class=p>:</span> <span class=n>CodeLLM</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=n>tokenizer</span><span class=p>:</span> <span class=n>CodeTokenizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=n>prompt</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=n>max_tokens</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>256</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    根据 prompt 生成代码
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        model: 训练好的模型
</span></span></span><span class=line><span class=cl><span class=s2>        tokenizer: tokenizer
</span></span></span><span class=line><span class=cl><span class=s2>        prompt: 代码提示，如函数签名
</span></span></span><span class=line><span class=cl><span class=s2>        max_tokens: 最大生成 token 数
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        生成的代码
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>device</span> <span class=o>=</span> <span class=nb>next</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span><span class=o>.</span><span class=n>device</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Encode prompt</span>
</span></span><span class=line><span class=cl>    <span class=n>input_ids</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>prompt</span><span class=p>)],</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 生成</span>
</span></span><span class=line><span class=cl>    <span class=n>output_ids</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>input_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>max_new_tokens</span><span class=o>=</span><span class=n>max_tokens</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>temperature</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>top_k</span><span class=o>=</span><span class=mi>40</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>top_p</span><span class=o>=</span><span class=mf>0.92</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>stop_tokens</span><span class=o>=</span><span class=p>[</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>token_to_id</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;&lt;EOS&gt;&#39;</span><span class=p>,</span> <span class=mi>3</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Decode</span>
</span></span><span class=line><span class=cl>    <span class=n>generated_code</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>output_ids</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>tolist</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>generated_code</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用示例</span>
</span></span><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=s1>&#39;&#39;&#39;def fibonacci(n: int) -&gt; int:
</span></span></span><span class=line><span class=cl><span class=s1>    &#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s1>    Calculate the nth Fibonacci number.
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>    Args:
</span></span></span><span class=line><span class=cl><span class=s1>        n: The position in Fibonacci sequence
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>    Returns:
</span></span></span><span class=line><span class=cl><span class=s1>        The nth Fibonacci number
</span></span></span><span class=line><span class=cl><span class=s1>    &#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s1>&#39;&#39;&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>generated</span> <span class=o>=</span> <span class=n>generate_code</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>tokenizer</span><span class=p>,</span> <span class=n>prompt</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>generated</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 可能的输出:</span>
</span></span><span class=line><span class=cl><span class=c1># def fibonacci(n: int) -&gt; int:</span>
</span></span><span class=line><span class=cl><span class=c1>#     &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=c1>#     Calculate the nth Fibonacci number.</span>
</span></span><span class=line><span class=cl><span class=c1>#     ...</span>
</span></span><span class=line><span class=cl><span class=c1>#     &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=c1>#     if n &lt;= 1:</span>
</span></span><span class=line><span class=cl><span class=c1>#         return n</span>
</span></span><span class=line><span class=cl><span class=c1>#     return fibonacci(n - 1) + fibonacci(n - 2)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># generated by hugo&#39;s coding agent</span>
</span></span></code></pre></div><h2 id=评估与改进方向>评估与改进方向</h2><h3 id=评估指标>评估指标</h3><table><thead><tr><th>指标</th><th>说明</th><th>目标值</th></tr></thead><tbody><tr><td>Perplexity</td><td>困惑度，越低越好</td><td>&lt; 10</td></tr><tr><td>Pass@k</td><td>生成代码通过测试的比例</td><td>> 30%</td></tr><tr><td>BLEU</td><td>与参考代码的相似度</td><td>> 0.3</td></tr><tr><td>Syntax Valid</td><td>语法正确率</td><td>> 95%</td></tr></tbody></table><h3 id=改进方向>改进方向</h3><ol><li><strong>扩大数据集</strong>：使用更多高质量的 Python 代码，如 GitHub 上星标高的项目</li><li><strong>增加模型参数</strong>：从 50M 扩展到 100M-300M</li><li><strong>引入代码结构信息</strong>：利用 AST 信息增强模型理解</li><li><strong>指令微调</strong>：使用 instruction-following 数据进行 SFT</li><li><strong>RLHF</strong>：通过人类反馈进一步优化生成质量</li></ol><h2 id=总结>总结</h2><p>本文从零开始实现了一个能够生成 Python 代码的小型语言模型。虽然与 CodeLlama、StarCoder 等大模型相比，我们的模型规模较小，但通过这个项目，你应该对以下内容有了深入理解：</p><ol><li><strong>代码 Tokenization</strong>：如何处理代码的特殊结构（缩进、关键字等）</li><li><strong>Transformer 架构</strong>：包括 RoPE、KV Cache、SwiGLU 等现代技术</li><li><strong>训练流程</strong>：数据准备、损失计算、优化器配置</li><li><strong>推理优化</strong>：Temperature、Top-k、Top-p 采样策略</li></ol><p>下一步，你可以尝试：</p><ul><li>在更大的数据集上训练</li><li>添加更多编程语言支持</li><li>实现 Fill-in-the-Middle (FIM) 能力</li><li>部署为 API 服务</li></ul><p>代码能力是 LLM 最重要的能力之一，理解其实现原理将帮助你更好地使用和优化这些模型。Happy coding!</p><div class=blog-tags><a href=https://hugozhu.site/tags/llm/>LLM</a>&nbsp;
<a href=https://hugozhu.site/tags/deep-learning/>deep-learning</a>&nbsp;
<a href=https://hugozhu.site/tags/python/>python</a>&nbsp;
<a href=https://hugozhu.site/tags/transformer/>transformer</a>&nbsp;
<a href=https://hugozhu.site/tags/code-generation/>code-generation</a>&nbsp;
<a href=https://hugozhu.site/tags/pytorch/>pytorch</a>&nbsp;</div><hr><section id=social-share><div class="list-inline footer-links"><div class=share-box aria-hidden=true><ul class=share><li><a href="//twitter.com/share?url=https%3a%2f%2fhugozhu.site%2fpost%2f2026%2f120-build-code-llm-from-scratch%2f&amp;text=Step-by-Step%20%e5%ae%9e%e7%8e%b0%e4%b8%80%e4%b8%aa%e8%83%bd%e7%bc%96%e7%a8%8b%e7%9a%84%e5%a4%a7%e6%a8%a1%e5%9e%8b&amp;via=" target=_blank title="Share on Twitter"><i class="fab fa-twitter"></i></a></li><li><a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fhugozhu.site%2fpost%2f2026%2f120-build-code-llm-from-scratch%2f" target=_blank title="Share on Facebook"><i class="fab fa-facebook"></i></a></li><li><a href="//reddit.com/submit?url=https%3a%2f%2fhugozhu.site%2fpost%2f2026%2f120-build-code-llm-from-scratch%2f&amp;title=Step-by-Step%20%e5%ae%9e%e7%8e%b0%e4%b8%80%e4%b8%aa%e8%83%bd%e7%bc%96%e7%a8%8b%e7%9a%84%e5%a4%a7%e6%a8%a1%e5%9e%8b" target=_blank title="Share on Reddit"><i class="fab fa-reddit"></i></a></li><li><a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fhugozhu.site%2fpost%2f2026%2f120-build-code-llm-from-scratch%2f&amp;title=Step-by-Step%20%e5%ae%9e%e7%8e%b0%e4%b8%80%e4%b8%aa%e8%83%bd%e7%bc%96%e7%a8%8b%e7%9a%84%e5%a4%a7%e6%a8%a1%e5%9e%8b" target=_blank title="Share on LinkedIn"><i class="fab fa-linkedin"></i></a></li><li><a href="//www.stumbleupon.com/submit?url=https%3a%2f%2fhugozhu.site%2fpost%2f2026%2f120-build-code-llm-from-scratch%2f&amp;title=Step-by-Step%20%e5%ae%9e%e7%8e%b0%e4%b8%80%e4%b8%aa%e8%83%bd%e7%bc%96%e7%a8%8b%e7%9a%84%e5%a4%a7%e6%a8%a1%e5%9e%8b" target=_blank title="Share on StumbleUpon"><i class="fab fa-stumbleupon"></i></a></li><li><a href="//www.pinterest.com/pin/create/button/?url=https%3a%2f%2fhugozhu.site%2fpost%2f2026%2f120-build-code-llm-from-scratch%2f&amp;description=Step-by-Step%20%e5%ae%9e%e7%8e%b0%e4%b8%80%e4%b8%aa%e8%83%bd%e7%bc%96%e7%a8%8b%e7%9a%84%e5%a4%a7%e6%a8%a1%e5%9e%8b" target=_blank title="Share on Pinterest"><i class="fab fa-pinterest"></i></a></li></ul></div></div></section><h4 class=see-also>See also</h4><ul><li><a href=/post/2026/117-how-to-benchmark-meeting-minutes-agent/>如何对会议纪要 Agent 进行 Benchmark？完整指南与实践</a></li><li><a href=/post/2026/114-agent-reinforcement-learning-best-practices/>Agent强化学习的最佳实践：并行任务处理与性能优化</a></li><li><a href=/post/2026/116-notebooklm-key-capabilities-and-architecture/>NotebookLM的核心能力与构建之道</a></li><li><a href=/post/2026/115-zhipu-slime-enterprise-ai-value/>智谱开源Slime：企业AI应用的强化学习利器</a></li><li><a href=/post/2025/113-claude-code-auto-correction-agent-loop/>Claude Code自动修正生成代码的原理解析：Agent Loop最佳实践</a></li></ul></article><ul class="pager blog-pager"><li class=previous><a href=https://hugozhu.site/post/2026/121-desktop-screen-recording-rpa-best-practices/ data-toggle=tooltip data-placement=top title="通过桌面录屏实现自动化 RPA 的最佳实践">&larr; Previous Post</a></li></ul><div class=disqus-comments><button id=show-comments class="btn btn-default" type=button>Show <span class=disqus-comment-count data-disqus-url=https://hugozhu.site/post/2026/120-build-code-llm-from-scratch>comments</span></button><div id=disqus_thread></div><script type=text/javascript>var disqus_config=function(){this.page.url="https://hugozhu.site/post/2026/120-build-code-llm-from-scratch"}</script></div></div></div></div><footer><div class=container><div class=row><div class=disclaimer><b>Disclaimer:</b> The opinions expressed herein are my own personal opinions and do not represent my company’s view in any way.</div></div><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center footer-links"></ul><p class="credits copyright text-muted">&nbsp;&bull;&nbsp;&copy;
2026
&nbsp;&bull;&nbsp;
<a href=https://hugozhu.site/>All about Raspberry Pi</a></p><p class="credits theme-by text-muted"><a href=https://gohugo.io>Hugo v0.145.0</a> powered &nbsp;&bull;&nbsp; Theme <a href=https://github.com/halogenica/beautifulhugo>Beautiful Hugo</a> adapted from <a href=https://deanattali.com/beautiful-jekyll/>Beautiful Jekyll</a></p></div></div></div></footer><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js integrity=sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><script src=https://code.jquery.com/jquery-3.7.0.slim.min.js integrity=sha384-w5y/xIeYixWvfM+A1cEbmHPURnvyqmVg5eVENruEdDjcyRLUSNej7512JQGspFUr crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/js/bootstrap.min.js integrity=sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd crossorigin=anonymous></script><script src=https://hugozhu.site/js/main.js></script><script src=https://hugozhu.site/js/highlight.min.js></script><script>hljs.initHighlightingOnLoad()</script><script>$(document).ready(function(){$("pre.chroma").css("padding","0")})</script><script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js integrity=sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js integrity=sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q crossorigin=anonymous></script><script src=https://hugozhu.site/js/load-photoswipe.js></script><script>(function(){var t,n="617d351a633194d48",e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="https://cse.google.com/cse.js?cx="+n,t=document.getElementsByTagName("script")[0],t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>$(function(){$("#show-comments").on("click",function(){var e="hugozhu";(function(){var t=document.createElement("script");t.type="text/javascript",t.async=!0,t.src="//"+e+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(t)})(),$(this).hide()})})</script><script id=dsq-count-scr src=//hugozhu.disqus.com/count.js async></script></body></html>